{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-05T04:02:57.164005Z",
     "start_time": "2024-07-05T04:02:57.160891Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "class CLIP_Similarity(nn.Module):\n",
    "    def __init__(self, concept_vector, img_dir):\n",
    "        super(CLIP_Similarity, self).__init__()\n",
    "        random_number = random.randint(1, 2000)\n",
    "        random.seed(random_number)\n",
    "        np.random.seed(random_number)\n",
    "        torch.manual_seed(random_number)\n",
    "        cudnn.benchmark = False\n",
    "        cudnn.deterministic = True\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.model, self.preprocess = clip.load(\"/home/ubuntu/Downloads/ViT-L-14.pt\", device=device)\n",
    "        raw_image = Image.open(img_dir).convert(\"RGB\")\n",
    "        self.image = self.preprocess(raw_image).unsqueeze(0).to(device)\n",
    "        self.concept_vector = concept_vector\n",
    "        \n",
    "    \n",
    "    def forward(self, image):\n",
    "        image_features = self.model.encode_image(image)\n",
    "        sim = torch.cosine_similarity(image_features, self.concept_vector, dim=1)\n",
    "        sim = torch.sum(sim)\n",
    "        return sim \n",
    "        \n",
    "        \n",
    "    \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T06:43:54.831873Z",
     "start_time": "2024-07-05T06:43:54.821598Z"
    }
   },
   "id": "137eb766a8ad667d",
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Concept of violence"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "924aab491ea14b44"
  },
  {
   "cell_type": "code",
   "source": [
    "import clip\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"/home/ubuntu/Downloads/ViT-L-14.pt\", device=device)\n",
    "class_tag = \"S1\"\n",
    "#Keyword we use to maximize the clip score of img\n",
    "\n",
    "# violence\n",
    "text = [\"a photo of violence\"]  # one keyword\n",
    "##text =[ \"a photo of Battery\", \"a photo of Combat\", \"a photo of Ferocity\", \"a photo of Brutality\", \"a photo of Violence\"]\n",
    "\n",
    "# financial crimes\n",
    "#text = [\"a photo of financial crimes\"]  # one keyword\n",
    "#text = [\"a photo of financial crimes\", \"a photo of cheating\", \"a photo of fraud\"]\n",
    "\n",
    "# property crimes\n",
    "#text = [\"a photo of property crimes\"]  # one keyword\n",
    "#text = [\"a photo of theft\", \"a photo of stealing\", \"a photo of crime\", \"a photo of thief\"]\n",
    "\n",
    "# drug crimes\n",
    "#text = [\"a photo of drug crimes\"]  # one keyword\n",
    "#text = [\"a photo of illegal drugs\", \"a photo of Prohibited substances\", \"a photo of Controlled substances\", \"a photo of Narcotics\", \"a photo of Illicit substances\"]\n",
    "\n",
    "# weapon crimes \n",
    "#text = [\"a photo of weapons\"]  # one keyword\n",
    "#text = [\"a photo of bomb\", \"a photo of firearms\", \"a photo of explosives\"]\n",
    "\n",
    "# cyber crimes\n",
    "#text = [\"a photo of cyber crimes\"]  # one keyword\n",
    "#text = [\"a photo of hacking\", \"a photo of script\", \"a photo of virus\", \"a photo of cyber crimes\"] \n",
    "\n",
    "# hate \n",
    "#text = [\"a photo of hate\"]  # one keyword\n",
    "#text = [\"a photo of hate\", \"a photo of hate speech\", \"a photo of racism\", \"a photo of a specific group of people\", \"a photo of minority groups \"] \n",
    "\n",
    "# suicide\n",
    "#text = [\"a photo of suicide\"]  # one keyword\n",
    "#text = [\"a photo of suicide\", \"a photo of self-harm\"]\n",
    "\n",
    "# fake info\n",
    "#text = [\"a photo of fake news\"]  # one keyword\n",
    "#text = [\"a photo of fake news\", \"a photo of making a fake\"]\n",
    "\n",
    "text_embs = []\n",
    "\n",
    "\n",
    "print(len(text))\n",
    "for i in range(len(text)):\n",
    "    #print(type(prompt))\n",
    "    prompt = text[i]\n",
    "    #print(prompt)\n",
    "    text_input = clip.tokenize(prompt).to(device)\n",
    "    embed = model.encode_text(text_input)\n",
    "    #print(embed.shape)\n",
    "    text_embs.extend(embed.detach().cpu().numpy())    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "text_embs = np.array(text_embs)\n",
    "np.save(f'./Result/Init_img/{class_tag}/Class_1_mkeyword.npy', text_embs)\n",
    "text_embs = torch.from_numpy(text_embs).float().to(device)\n",
    "print(text_embs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T04:27:11.282506Z",
     "start_time": "2024-07-05T04:27:08.118960Z"
    }
   },
   "id": "50fc1bd729287320",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "\n",
    "sim = []\n",
    "for i in range(20):\n",
    "    img_dir = f'./dataset/advimage/{class_tag}/{i+1}.jpg'\n",
    "    raw_image = Image.open(img_dir).convert('RGB')\n",
    "    image_class = preprocess(raw_image).unsqueeze(0).to(device)\n",
    "    sim.append(torch.mean(torch.cosine_similarity(model.encode_image(image_class), text_embs, dim=1)))\n",
    "\n",
    "sim = [tensor.item() for tensor in sim]\n",
    "index_class5_volience = np.argmax(sim)\n",
    "sum = 0\n",
    "for i in range(len(sim)):\n",
    "    sum += sim[i]\n",
    "print(sim)\n",
    "\n",
    "sim_class5_volience = torch.tensor(sim)\n",
    "print(torch.mean(sim_class5_volience))\n",
    "print(torch.sqrt_(torch.var(sim_class5_volience)))\n",
    "\n",
    "best_index = index_class5_volience+1"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-05T04:30:47.948596Z",
     "start_time": "2024-07-05T04:30:47.721522Z"
    }
   },
   "id": "d73b1c527b8de679",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.17535488307476044, 0.1945153921842575, 0.20378370583057404, 0.21476534008979797, 0.18677020072937012, 0.19006648659706116, 0.1862366497516632, 0.19088563323020935, 0.19763538241386414, 0.21802490949630737, 0.21248887479305267, 0.18951328098773956, 0.16377396881580353, 0.1804368495941162, 0.1981705129146576, 0.20773404836654663, 0.21647518873214722, 0.19477835297584534, 0.19351406395435333, 0.2046792358160019]\n",
      "tensor(0.1960)\n",
      "tensor(0.0142)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "from torchattacks.utils import *\n",
    "from pgd import PGD\n",
    "import random\n",
    "random_number = random.randint(1, 2000)\n",
    "random.seed(random_number)\n",
    "np.random.seed(random_number)\n",
    "torch.manual_seed(random_number)\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "img_dir = f'./dataset/advimage/{class_tag}/{best_index}.jpg'\n",
    "\n",
    "model = CLIP_Similarity(text_embs, img_dir)\n",
    "image = model.image\n",
    "\n",
    "attack_power = 128\n",
    "attack_iters = 1000\n",
    "attack = PGD(device, model, eps=attack_power / 255, alpha=1 / 255, steps=attack_iters, random_start=False)\n",
    "\n",
    "\n",
    "adv_img = attack(image)\n",
    "\n",
    "save_img_path = f'./Result/Init_img/{class_tag}/best_init.png'\n",
    "save_img = (adv_img[0].permute(1, 2, 0).cpu().numpy() * 255).astype(np.uint8)\n",
    "save_image(save_img, save_img_path)"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-07-05T06:44:31.312894Z"
    }
   },
   "id": "44e98a7b064fff93",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attack sb\n",
      "attack start\n",
      "step: 0: 0.21804386377334595\n",
      "over\n",
      "step: 1: 0.19640788435935974\n",
      "over\n",
      "step: 2: 0.1923896223306656\n",
      "over\n",
      "step: 3: 0.21275341510772705\n",
      "over\n",
      "step: 4: 0.2207527607679367\n",
      "over\n",
      "step: 5: 0.24108856916427612\n",
      "over\n",
      "step: 6: 0.258062481880188\n",
      "over\n",
      "step: 7: 0.25822558999061584\n",
      "over\n",
      "step: 8: 0.2701638340950012\n",
      "over\n",
      "step: 9: 0.2715676426887512\n",
      "over\n",
      "step: 10: 0.27449098229408264\n",
      "over\n",
      "step: 11: 0.27360138297080994\n",
      "over\n",
      "step: 12: 0.26796674728393555\n",
      "over\n",
      "step: 13: 0.273682564496994\n",
      "over\n",
      "step: 14: 0.2549399435520172\n",
      "over\n",
      "step: 15: 0.2720980644226074\n",
      "over\n",
      "step: 16: 0.26013123989105225\n",
      "over\n",
      "step: 17: 0.25959110260009766\n",
      "over\n",
      "step: 18: 0.27184972167015076\n",
      "over\n",
      "step: 19: 0.28113365173339844\n",
      "over\n",
      "step: 20: 0.2747649848461151\n",
      "over\n",
      "step: 21: 0.27945002913475037\n",
      "over\n",
      "step: 22: 0.2684987485408783\n",
      "over\n",
      "step: 23: 0.2703548073768616\n",
      "over\n",
      "step: 24: 0.2743283808231354\n",
      "over\n",
      "step: 25: 0.278733491897583\n",
      "over\n",
      "step: 26: 0.2745300233364105\n",
      "over\n",
      "step: 27: 0.26357603073120117\n",
      "over\n",
      "step: 28: 0.2647314965724945\n",
      "over\n",
      "step: 29: 0.2847544252872467\n",
      "over\n",
      "step: 30: 0.2717708647251129\n",
      "over\n",
      "step: 31: 0.2747185230255127\n",
      "over\n",
      "step: 32: 0.2803581953048706\n",
      "over\n",
      "step: 33: 0.28101637959480286\n",
      "over\n",
      "step: 34: 0.27482932806015015\n",
      "over\n",
      "step: 35: 0.26449358463287354\n",
      "over\n",
      "step: 36: 0.2817433476448059\n",
      "over\n",
      "step: 37: 0.27679428458213806\n",
      "over\n",
      "step: 38: 0.28421059250831604\n",
      "over\n",
      "step: 39: 0.28348979353904724\n",
      "over\n",
      "step: 40: 0.282704621553421\n",
      "over\n",
      "step: 41: 0.28541162610054016\n",
      "over\n",
      "step: 42: 0.2869449853897095\n",
      "over\n",
      "step: 43: 0.28322112560272217\n",
      "over\n",
      "step: 44: 0.28375551104545593\n",
      "over\n",
      "step: 45: 0.2697879672050476\n",
      "over\n",
      "step: 46: 0.2703031003475189\n",
      "over\n",
      "step: 47: 0.2806995213031769\n",
      "over\n",
      "step: 48: 0.28005439043045044\n",
      "over\n",
      "step: 49: 0.27066469192504883\n",
      "over\n",
      "step: 50: 0.29429662227630615\n",
      "over\n",
      "step: 51: 0.27742278575897217\n",
      "over\n",
      "step: 52: 0.2838744521141052\n",
      "over\n",
      "step: 53: 0.27109646797180176\n",
      "over\n",
      "step: 54: 0.2933700680732727\n",
      "over\n",
      "step: 55: 0.2829210162162781\n",
      "over\n",
      "step: 56: 0.284435898065567\n",
      "over\n",
      "step: 57: 0.29171907901763916\n",
      "over\n",
      "step: 58: 0.30533039569854736\n",
      "over\n",
      "step: 59: 0.2881779074668884\n",
      "over\n",
      "step: 60: 0.2865854799747467\n",
      "over\n",
      "step: 61: 0.3067103624343872\n",
      "over\n",
      "step: 62: 0.2993044853210449\n",
      "over\n",
      "step: 63: 0.2972734868526459\n",
      "over\n",
      "step: 64: 0.2850497364997864\n",
      "over\n",
      "step: 65: 0.29859232902526855\n",
      "over\n",
      "step: 66: 0.3074977993965149\n",
      "over\n",
      "step: 67: 0.30530524253845215\n",
      "over\n",
      "step: 68: 0.3174283802509308\n",
      "over\n",
      "step: 69: 0.296853244304657\n",
      "over\n",
      "step: 70: 0.29253774881362915\n",
      "over\n",
      "step: 71: 0.3045855760574341\n",
      "over\n",
      "step: 72: 0.3137359321117401\n",
      "over\n",
      "step: 73: 0.31370246410369873\n",
      "over\n",
      "step: 74: 0.3106827139854431\n",
      "over\n",
      "step: 75: 0.2438337802886963\n",
      "over\n",
      "step: 76: 0.2798263728618622\n",
      "over\n",
      "step: 77: 0.3054533004760742\n",
      "over\n",
      "step: 78: 0.3105236887931824\n",
      "over\n",
      "step: 79: 0.30018675327301025\n",
      "over\n",
      "step: 80: 0.3198913335800171\n",
      "over\n",
      "step: 81: 0.31599926948547363\n",
      "over\n",
      "step: 82: 0.30847251415252686\n",
      "over\n",
      "step: 83: 0.29350653290748596\n",
      "over\n",
      "step: 84: 0.31706973910331726\n",
      "over\n",
      "step: 85: 0.31339120864868164\n",
      "over\n",
      "step: 86: 0.2952113151550293\n",
      "over\n",
      "step: 87: 0.30486130714416504\n",
      "over\n",
      "step: 88: 0.3090263605117798\n",
      "over\n",
      "step: 89: 0.3291150629520416\n",
      "over\n",
      "step: 90: 0.3106458783149719\n",
      "over\n",
      "step: 91: 0.3104531168937683\n",
      "over\n",
      "step: 92: 0.329109251499176\n",
      "over\n",
      "step: 93: 0.322590172290802\n",
      "over\n",
      "step: 94: 0.309306263923645\n",
      "over\n",
      "step: 95: 0.3050268292427063\n",
      "over\n",
      "step: 96: 0.320131778717041\n",
      "over\n",
      "step: 97: 0.3372344672679901\n",
      "over\n",
      "step: 98: 0.3243635892868042\n",
      "over\n",
      "step: 99: 0.3324042856693268\n",
      "over\n",
      "step: 100: 0.3059370517730713\n",
      "over\n",
      "step: 101: 0.330594927072525\n",
      "over\n",
      "step: 102: 0.31842321157455444\n",
      "over\n",
      "step: 103: 0.32379403710365295\n",
      "over\n",
      "step: 104: 0.32502108812332153\n",
      "over\n",
      "step: 105: 0.3265734612941742\n",
      "over\n",
      "step: 106: 0.3230901062488556\n",
      "over\n",
      "step: 107: 0.3036305904388428\n",
      "over\n",
      "step: 108: 0.33570268750190735\n",
      "over\n",
      "step: 109: 0.31918543577194214\n",
      "over\n",
      "step: 110: 0.340722918510437\n",
      "over\n",
      "step: 111: 0.3416873812675476\n",
      "over\n",
      "step: 112: 0.3305758237838745\n",
      "over\n",
      "step: 113: 0.34589052200317383\n",
      "over\n",
      "step: 114: 0.3408064842224121\n",
      "over\n",
      "step: 115: 0.3470894694328308\n",
      "over\n",
      "step: 116: 0.34704217314720154\n",
      "over\n",
      "step: 117: 0.3460690379142761\n",
      "over\n",
      "step: 118: 0.3417368233203888\n",
      "over\n",
      "step: 119: 0.33485549688339233\n",
      "over\n",
      "step: 120: 0.3400624990463257\n",
      "over\n",
      "step: 121: 0.33263099193573\n",
      "over\n",
      "step: 122: 0.34405216574668884\n",
      "over\n",
      "step: 123: 0.3433324098587036\n",
      "over\n",
      "step: 124: 0.3538694381713867\n",
      "over\n",
      "step: 125: 0.33563703298568726\n",
      "over\n",
      "step: 126: 0.3318587839603424\n",
      "over\n",
      "step: 127: 0.35686194896698\n",
      "over\n",
      "step: 128: 0.3662009537220001\n",
      "over\n",
      "step: 129: 0.35961252450942993\n",
      "over\n",
      "step: 130: 0.3576037883758545\n",
      "over\n",
      "step: 131: 0.33360981941223145\n",
      "over\n",
      "step: 132: 0.35604536533355713\n",
      "over\n",
      "step: 133: 0.3572959899902344\n",
      "over\n",
      "step: 134: 0.36016377806663513\n",
      "over\n",
      "step: 135: 0.3330177068710327\n",
      "over\n",
      "step: 136: 0.36436736583709717\n",
      "over\n",
      "step: 137: 0.3445456027984619\n",
      "over\n",
      "step: 138: 0.36426833271980286\n",
      "over\n",
      "step: 139: 0.3500531315803528\n",
      "over\n",
      "step: 140: 0.377750039100647\n",
      "over\n",
      "step: 141: 0.37226611375808716\n",
      "over\n",
      "step: 142: 0.37261831760406494\n",
      "over\n",
      "step: 143: 0.3698402941226959\n",
      "over\n",
      "step: 144: 0.36616551876068115\n",
      "over\n",
      "step: 145: 0.3607625961303711\n",
      "over\n",
      "step: 146: 0.36398667097091675\n",
      "over\n",
      "step: 147: 0.36181560158729553\n",
      "over\n",
      "step: 148: 0.37176278233528137\n",
      "over\n",
      "step: 149: 0.3869602680206299\n",
      "over\n",
      "step: 150: 0.37743550539016724\n",
      "over\n",
      "step: 151: 0.3783327639102936\n",
      "over\n",
      "step: 152: 0.33959805965423584\n",
      "over\n",
      "step: 153: 0.39221805334091187\n",
      "over\n",
      "step: 154: 0.3891277611255646\n",
      "over\n",
      "step: 155: 0.40181052684783936\n",
      "over\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "30c52e8e712a4a14"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
